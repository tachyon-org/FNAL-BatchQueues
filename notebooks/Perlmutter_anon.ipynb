{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae386ba8-8e9a-46fc-af97-78a1bc8e4794",
   "metadata": {},
   "source": [
    "## Perlmutter Anon. Code ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55db265e-cea9-46b3-909c-a60b3481b2e0",
   "metadata": {},
   "source": [
    "#### Anon. These fields: User, Account ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e66c1a-89c4-4d57-b73a-516b2190adde",
   "metadata": {},
   "source": [
    "#### Imports ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62f3c4ec-2115-4015-9f62-7b04c726c3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Anonymize CSV job data.\n",
    "\n",
    "- Reads input files\n",
    "- Writes anonymized copies\n",
    "- Replaces Seq.:\n",
    "    User    -> UR_1, UR_2, ...\n",
    "    Account -> AC_1, AC_2, ...\n",
    "  Global mapping across ALL processed files.\n",
    "- Writes JSON mapping for tracing.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3c29e4-ffab-410b-9de0-f629441174a5",
   "metadata": {},
   "source": [
    "#### Token Mapper ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4580c151-a7eb-40a4-aea4-928af5e1fab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class TokenRecord:\n",
    "    token: str\n",
    "    count: int\n",
    "    valid: bool\n",
    "\n",
    "\n",
    "class GarbleTokenMapper:\n",
    "    def __init__(self, prefix: str = \"UR_\", start: int = 1):\n",
    "        self.prefix = str(prefix)\n",
    "        self.start = int(start)\n",
    "        self._by_orig: Dict[str, TokenRecord] = {}\n",
    "        self._token_to_orig: Dict[str, str] = {}\n",
    "        self._counter = self.start - 1\n",
    "\n",
    "    def _next_token(self) -> str:\n",
    "        self._counter += 1\n",
    "        return f\"{self.prefix}{self._counter}\"\n",
    "\n",
    "    def add(self, original: str, *, valid: bool = True) -> str:\n",
    "        if original is None:\n",
    "            return original\n",
    "        key = str(original).strip()\n",
    "        if not key:\n",
    "            return original\n",
    "        if key in self._by_orig:\n",
    "            rec = self._by_orig[key]\n",
    "            rec.count += 1\n",
    "            return rec.token\n",
    "        tok = self._next_token()\n",
    "        rec = TokenRecord(token=tok, count=1, valid=bool(valid))\n",
    "        self._by_orig[key] = rec\n",
    "        self._token_to_orig[tok] = key\n",
    "        return tok\n",
    "\n",
    "    def to_jsonable(self) -> dict:\n",
    "        entries = []\n",
    "        for orig, rec in self._by_orig.items():\n",
    "            item = asdict(rec)\n",
    "            item[\"original\"] = orig\n",
    "            entries.append(item)\n",
    "        return {\n",
    "            \"prefix\": self.prefix,\n",
    "            \"start\": self.start,\n",
    "            \"counter\": self._counter,\n",
    "            \"entries\": entries,\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90b60ca-954d-4621-9bbe-346e4518229d",
   "metadata": {},
   "source": [
    "#### Core Processing ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "451efd97-4015-40aa-8c6d-56921281fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def anonymize_dataframe(df: pd.DataFrame,\n",
    "                        user_mapper: GarbleTokenMapper,\n",
    "                        account_mapper: GarbleTokenMapper) -> pd.DataFrame:\n",
    "    out_df = df.copy()\n",
    "\n",
    "    if \"User\" in out_df.columns:\n",
    "        out_df[\"User\"] = [\n",
    "            user_mapper.add(str(v).strip(), valid=True) if str(v).strip() else str(v).strip()\n",
    "            for v in out_df[\"User\"]\n",
    "        ]\n",
    "\n",
    "    if \"Account\" in out_df.columns:\n",
    "        out_df[\"Account\"] = [\n",
    "            account_mapper.add(str(v).strip(), valid=True) if str(v).strip() else str(v).strip()\n",
    "            for v in out_df[\"Account\"]\n",
    "        ]\n",
    "\n",
    "    return out_df\n",
    "\n",
    "\n",
    "def process_file(input_path: Path,\n",
    "                 output_path: Path,\n",
    "                 user_mapper: GarbleTokenMapper,\n",
    "                 account_mapper: GarbleTokenMapper) -> None:\n",
    " \n",
    "    df = pd.read_csv(input_path, dtype={\"Reservation\": str, \"FailedNode\": str}, low_memory=False)\n",
    "\n",
    "    df_anon = anonymize_dataframe(df, user_mapper, account_mapper)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_anon.to_csv(output_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "def build_mapping_json(user_mapper: GarbleTokenMapper,\n",
    "                       account_mapper: GarbleTokenMapper) -> dict:\n",
    "    return {\n",
    "        \"users\": user_mapper.to_jsonable(),\n",
    "        \"accounts\": account_mapper.to_jsonable(),\n",
    "        \"meta\": {\n",
    "            \"description\": \"Mapping from original User/Account to anonymized names (UR_n / AC_n)\",\n",
    "        },\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6811e27e-70ae-4c64-b6f7-c946b26f15cf",
   "metadata": {},
   "source": [
    "#### Directory ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d331022-96a3-4b0a-bc4b-df30a89d2330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anonymized files written under: /home/nathan/git/FNAL-BatchQueues/notebooks/PelmutterOutput\n",
      "Mapping written to: /home/nathan/git/FNAL-BatchQueues/notebooks/PelmutterOutput/perlmutter_user_account_map.json\n",
      "Script directory: /home/nathan/git/FNAL-BatchQueues/notebooks\n",
      "Expected input root: /home/nathan/git/FNAL-BatchQueues/perlmutter_data\n"
     ]
    }
   ],
   "source": [
    "def main() -> None:\n",
    "\n",
    "    try:\n",
    "        script_dir = Path(__file__).resolve().parent\n",
    "    except NameError:\n",
    "        script_dir = Path.cwd()\n",
    "\n",
    "\n",
    "    input_root = (script_dir.parent / \"perlmutter_data\").resolve()\n",
    "\n",
    "    output_root = script_dir / \"PelmutterOutput\"\n",
    "    output_root.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    user_mapper = GarbleTokenMapper(prefix=\"UR_\", start=1)\n",
    "    account_mapper = GarbleTokenMapper(prefix=\"AC_\", start=1)\n",
    "\n",
    "    if not input_root.exists():\n",
    "        raise FileNotFoundError(f\"Input root does not exist: {input_root}\")\n",
    "\n",
    "    for year_dir in sorted(input_root.iterdir()):\n",
    "        if not year_dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        rel_year = year_dir.relative_to(input_root)\n",
    "        out_year_dir = output_root / rel_year\n",
    "        out_year_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for in_file in sorted(year_dir.iterdir()):\n",
    "            if not in_file.is_file():\n",
    "                continue\n",
    "            if in_file.suffix.lower() not in {\".csv\", \".txt\"}:\n",
    "                continue\n",
    "\n",
    "            rel_path = in_file.relative_to(input_root)\n",
    "            out_file = output_root / rel_path\n",
    "\n",
    "            process_file(in_file, out_file, user_mapper, account_mapper)\n",
    "\n",
    "    mapping = build_mapping_json(user_mapper, account_mapper)\n",
    "    mapping_path = output_root / \"perlmutter_user_account_map.json\"\n",
    "    with mapping_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(mapping, f, indent=2)\n",
    "\n",
    "    print(f\"Anonymized files written under: {output_root}\")\n",
    "    print(f\"Mapping written to: {mapping_path}\")\n",
    "    print(\"Script directory:\", script_dir)\n",
    "    print(\"Expected input root:\", input_root)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3fa7a1-20b5-4b6c-9461-156c00594073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
